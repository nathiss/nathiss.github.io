[{"content":"Recently I\u0026rsquo;m investing a lot of time to developing a game server in Rust. I started with implementing network layer based on WebSockets. It\u0026rsquo;s far from being ready, but I developed a helper crate for creating detached, cancellable services.\nGame server backstory The idea of developing an authoritative game server always seemed appealing to me. Network programming, however, has many pitfalls:\nServer need to validate all use inputs to protect game state from bad actors. Ill-formed data sent by one client should not deny service for another player. Async programming is hard in general. So, in the past I have had many attempts to develop a game server. Each improving on mistakes made in the previous one.\nspectrum-old \u0026ndash; A real-time multiplayer browser game, Fusion-cpp \u0026ndash; This is the source code of the server for the Fusion game, [private repo], [private repo], [private repo]. And now I\u0026rsquo;m working on another. üëç\nThis time, improvements over the previous one are creating implementation that depend on traits and organizing TODOs to a single GitHub project.\nMaking Progressxkcd #1906\nCancellable crate Network functionalities in game servers (listeners, TCP streams, etc.) await for some input and usually yield a result.\nComponent Input Output Listener new incoming connection Client object TCP Stream data package parsed ClientMessage model Ping service timer tick new ping frame We can define a trait that will describe common interface for all of them:\n#[async_trait::async_trait] pub trait Cancellable { type Result; type Error; async fn run(\u0026amp;mut self) -\u0026gt; Result\u0026lt;CancellationResult\u0026lt;Self::Result\u0026gt;, Self::Error\u0026gt;; } Method run performs a single unit of work of the service. Internally it can await for the input to be available and then return its result. If the returned value is Err(Self::Error) then the service completes. If it succeeds, then it should return Ok(CancellationResult). CancellationResult is an enum defined as follows:\npub enum CancellationResult\u0026lt;T\u0026gt; { Item(T), Continue, Break, } impl\u0026lt;T\u0026gt; CancellationResult\u0026lt;T\u0026gt; { pub fn item(t: impl Into\u0026lt;T\u0026gt;) -\u0026gt; Self { Self::Item(t.into()) } } Enum\u0026rsquo;s variant control whether the service will continue to perform its work. If the service produces a value, then it should wrap it as CancellableResult::Item(t); it\u0026rsquo;s also a signal that the service should continue to work. If no value is available, but the service should continue then it returns CancellableResult::Continue (similar to Poll::Pending).\nIf the service finishes its work successfully (e.g. when the peer closes the connection) then the service should return CancellableResult::Break.\nCancellable trait has methods for spawning the service as a detached, background task:\n#[async_trait::async_trait] pub trait Cancellable { // ... async fn spawn(mut self, cancellation_token: CancellationToken) -\u0026gt; CancellableHandle\u0026lt;Self\u0026gt; { // ... } async fn spawn_with_callback\u0026lt;F\u0026gt;( mut self, cancellation_token: CancellationToken, mut callback: F, ) -\u0026gt; CancellableHandle\u0026lt;Self\u0026gt; where F: FnMut(Self::Result) -\u0026gt; Result\u0026lt;(), Self::Result\u0026gt; { // ... } } Both return a handle, which can be awaited for the service to complete, once it has been cancelled!\nIf the service produces results, then it can be spawned with spawn_with_callback, to consume them. If the callback returns Err(Self::Result) then the service completes immediately.\nThis setup offers a way of detaching services which perform work \u0026ldquo;on their own\u0026rdquo;, but sometimes services need to accept additional data. An example is TCP stream: it reads data packages from a peer and consumes them via callback. However, if the server decides the connection should be terminated, then the service should complete its work.\nEnter\u0026hellip;\nCommunicating with detached service When we spawn the service task we already get a handle:\nlet token = CancellableToken::new(); let handle = service.spawn(token.clone()).await; The handle can be used as an interface to send data to its service.\nhandle.update(ConnectionStatus::TerminatedByServer(reason)); The actual interface needs to be implementation-dependent \u0026ndash; defined in the Cancellable trait. By easily extending the trait we get:\n#[async_trait::async_trait] pub trait Cancellable { // ... type Handle; async fn new_handle(\u0026amp;mut self) -\u0026gt; Self::Handle; } When the service is spawned (either by spawn or spawn_with_callback), the method will call new_handle to construct the handle. The handle is owned by CancellableHandle, which implements Deref for Self::Handle type. With that setup, we can define a channel by which spawner can communicate with spawnee.\nI like the final product, so I\u0026rsquo;ve packaged it as a crate. It\u0026rsquo;s available on crates.io.\nüåä\n","permalink":"https://madebyme.today/articles/cancellable/","summary":"Recently I\u0026rsquo;m investing a lot of time to developing a game server in Rust. I started with implementing network layer based on WebSockets. It\u0026rsquo;s far from being ready, but I developed a helper crate for creating detached, cancellable services.\n","tag":"Rust","title":"Cancellable"},{"content":"Natural Selection is what allows our species (and images!) to improve over time. In this article we\u0026rsquo;ll implement a scoring mechanism, through which \u0026ldquo;Mona Lisa\u0026rdquo; will actually look like one.\nNatural Selection Natural selection is the process though which species adapt to their environments. If the evolution is a wheel, then natural selection is the force that spins it. Organism that are better adapted tend to produce more offspring and pass on their genes. This process favours genes that aided their bearers to survive/reproduce, increasing their number in the following generations.\nIn biology \u0026ldquo;fitness\u0026rdquo; is defined by how successful an organism is at reproduction.\nWikipedia says:\nIf an organism lives half as long as others of its species, but has twice as many offspring surviving to adulthood, its genes become more common in the adult population of the next generation.\n\u0026hellip; and also \u0026hellip;\nIt is also equal to the average contribution to the gene pool of the next generation, made by the same individuals of the specified genotype or phenotype.\nWe, however, will define \u0026ldquo;fitness\u0026rdquo; as a difference between an organism and the ideal. Which is a bit vague, as there\u0026rsquo;s no obvious way of substituting one image from another and produce an integer. We\u0026rsquo;ll get back to that in a bit.\nLoss functions Genetic Algorithms (and Evolutionary Algorithms) are optimization algorithms that need a \u0026ldquo;goodness\u0026rdquo; of an organism, in order to decide whether to discard it. We\u0026rsquo;re going to implement two scoring methods, both based on loss functions. L1 Loss Function and L2 Loss Function are defined as follows:\n$$ L1 = \\sum_{i=0}^n \\vert y_{true_i} - y_{predicted_i} \\vert \\newline L2 = \\sum_{i=0}^n \\left( y_{true_i} - y_{predicted_i} \\right)^2 $$\nn represents the size of the ideal image in pixels; we know, that both images have the exact same size, so it will never out-of-range.\nBoth of these functions are used to covert an \u0026ldquo;object\u0026rdquo; or an \u0026ldquo;event\u0026rdquo;, to a real number representing its score. Which one should be picked then? In general L2 Loss Function is preferred in most of the cases. However, when the dataset has outliers, then L2 Loss Function does not perform well \u0026ndash; it leads to much larger errors.\nCool, we have a way of calculating differences between images\u0026rsquo; pixels. But how to calculate a difference between two pixels? That question was already answered in Art From Chaos. We take each of the pixels color channels and calculate their differences.\n$$ f(O, S) = \\sum_{i=0}^n \\vert (r_2 - r_1)^2 + (g_2 - g_1)^2 + (b_2 - b_1)^2 \\vert $$\nScoring mechanism First, let\u0026rsquo;s define a trait whereby the rest of the system will be able to interact with scoring methods.\npub trait FitnessFunction { /// This method calculates the fitness of `second_image` relative to `first_image`. /// /// In other words, it returns a value describing difference between those two images. The higher the value, the /// more those images are different from each other. fn calculate_fitness(\u0026amp;self, first_image: \u0026amp;Image, second_image: \u0026amp;Image) -\u0026gt; usize; } The method assumes that the first_image is the one being scored and second_image is the ideal. However, what\u0026rsquo;s nice about these loss functions, is that they return absolute values \u0026ndash; it does not matter which parameter is the ideal.\n// True for both L1 and L2 assert_eq!( scorer.calculate_fitness(first_image, second_image), scorer.calculate_fitness(second_image, first_image) ); Implementation of L1: AbsoluteDistance The implementation isn\u0026rsquo;t complex - first we fold each pixel pair to a usize, and then we sum those parts together to produce the score. Actually, we can do both by using Iterator\u0026rsquo;s fold method.\nfn fold_pixels(mut sum: usize, (p1, p2): (\u0026amp;Pixel, \u0026amp;Pixel)) -\u0026gt; usize { let diff_r = isize::from(p1.get_r()) - isize::from(p2.get_r()); let diff_g = isize::from(p1.get_g()) - isize::from(p2.get_g()); let diff_b = isize::from(p1.get_b()) - isize::from(p2.get_b()); sum += diff_r.unsigned_abs(); sum += diff_g.unsigned_abs(); sum += diff_b.unsigned_abs(); sum } #[derive(Debug, Default)] pub struct AbsoluteDistance; impl FitnessFunction for AbsoluteDistance { fn calculate_fitness( \u0026amp;self, first_image: \u0026amp;crate::models::Image, second_image: \u0026amp;crate::models::Image, ) -\u0026gt; usize { first_image .pixels() .iter() .zip(second_image.pixels().iter()) .fold(0usize, fold_pixels) } } Implementation of L2: SquareDistance Implementation of SquareDistance is almost identical. The only difference is the squaring of color channels.\nfn fold_pixels(mut sum: usize, (p1, p2): (\u0026amp;Pixel, \u0026amp;Pixel)) -\u0026gt; usize { let diff_r = isize::from(p1.get_r()) - isize::from(p2.get_r()); let diff_g = isize::from(p1.get_g()) - isize::from(p2.get_g()); let diff_b = isize::from(p1.get_b()) - isize::from(p2.get_b()); sum += diff_r.pow(2) as usize; sum += diff_g.pow(2) as usize; sum += diff_b.pow(2) as usize; sum } #[derive(Debug, Default)] pub struct SquareDistance; impl FitnessFunction for SquareDistance { fn calculate_fitness( \u0026amp;self, first_image: \u0026amp;crate::models::Image, second_image: \u0026amp;crate::models::Image, ) -\u0026gt; usize { first_image .pixels() .iter() .zip(second_image.pixels().iter()) .fold(0usize, fold_pixels) } } Fixing \u0026ldquo;Mona Lisa\u0026rdquo; Let\u0026rsquo;s wire up the scoring component with generation\u0026rsquo;s flow. During each generation, every specimens will be scored relatively to the ideal image. Using the scores we will select the best 51 organisms and discard the rest.\nSince there\u0026rsquo;s no crossover functionality yet, we need to fill the emptied generation space somehow. Simplest solution: once we have 5 best specimens, we\u0026rsquo;ll copy them over multiple times, to get a new generation 100 strong.\nMona Lisa (generation #10 000) ü§å\nThe image does look recognizable. And it\u0026rsquo;s still missing the last part \u0026ndash; crossing. However, as it\u0026rsquo;s not \u0026ldquo;required\u0026rdquo;, the algorithm works and it produces acceptable results.\nNext, we\u0026rsquo;ll implement the crossing function and we\u0026rsquo;ll see how much it improves algorithm\u0026rsquo;s efficiency \u0026ndash; defined as the derivative of specimen score with respect to generation number.\nPhoto by Fernando Venzano on Unsplash\nWhy 5? No particular reason. There should be enough specimen to fill the generation space again by combining them in varied ways. It could be more than 5, but we need to remember, that the goal of dropping those \u0026ldquo;bad\u0026rdquo; images is to discard mutations that resulted in decreasing overall \u0026ldquo;goodness\u0026rdquo;.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://madebyme.today/articles/franklin/natural-selection-and-loss-functions/","summary":"Natural Selection is what allows our species (and images!) to improve over time. In this article we\u0026rsquo;ll implement a scoring mechanism, through which \u0026ldquo;Mona Lisa\u0026rdquo; will actually look like one.\n","tag":"Rust","title":"Natural Selection and Loss Functions"},{"content":"In the previous article from this series, we\u0026rsquo;ve talked about genetic algorithms and how they can be used to generate art. Now let\u0026rsquo;s put those ideas into action and focus on implementing the first part of our artistic toolset: mutators.\nPreparing the ecosystem Before we begin working on mutators, we need to prepare an environment in which our specimens can thrive. We don\u0026rsquo;t need much - right now the only thing is a generation. For the record, in this context, a generation is a collection of specimen which can be mutated, scored, and bred (basically experimented upon) to get us closer to the optimum. Since our specimens are images, they can be represented by the following structs:\nstruct Pixel { r: u8, g: u8, b: u8, } struct Image { height: usize, width: usize, pixels: Vec\u0026lt;Pixel\u0026gt;, } Representing each pixel as a 24-bit value gives us some flexibility here \u0026ndash; it allows us to operate on two color depths: true color (which uses 24-bit colors) and grayscale (8-bit). Creating a grayscale pixel can be done by setting up all color channels to the same value. True, it uses thrice as much memory as it could, but\u0026hellip;\nPremature optimization is the root of all evil.\n~ Donald Knuth\nMethod of initializing1 the generation will affect how fast we can search the solution space. As the algorithm produces more fitted images, the specimens get closed to the source image. But we don\u0026rsquo;t really care about how fast the optimum can be achieved, frankly, we don\u0026rsquo;t really care about achieving the optimum in the first place. It is the process of getting more fitted images and seeing how they evolve what\u0026rsquo;s really interesting. Therefore our generation will be initialized by blank images - images filled by white pixels. It will reduce pace of solution space search, but will produce images that are more visually interesting. We are here to do art, after all. üé®\nimpl Pixel { #[must_use] pub const fn white() -\u0026gt; Self { Pixel::new(255, 255, 255) } #[must_use] pub const fn new(r: u8, g: u8, b: u8) -\u0026gt; Self { Pixel { r, g, b } } } impl Image { #[must_use] pub fn new(height: usize, width: usize, pixels: Vec\u0026lt;Pixel\u0026gt;) -\u0026gt; Self { Self { height, width, pixels, } } #[must_use] pub fn blank(height: usize, width: usize, pixel: \u0026amp;Pixel) -\u0026gt; Self { let size = height * width; let pixels = vec![pixel.clone(); size]; Self::new(height, width, pixels) } } #[must_use] fn get_first_generation( vec_len: usize, image_height: usize, image_width: usize ) -\u0026gt; Vec\u0026lt;Image\u0026gt; { let pixel = Pixel::white(); vec![Image::blank(height, width, \u0026amp;pixel); vec_len] } This code takes care of initializing the generation. üëå\nThrowing dice and hoping for the best As was mentioned in the previous article, mutators act only on one specimen at a time, inserting random modification onto it. With that description alone, we can already define a contract for all mutators we\u0026rsquo;re going to implement:\npub trait Mutator { fn mutate(\u0026amp;self, image: \u0026amp;mut Image); } Why \u0026amp;self and not \u0026amp;mut self? Due to the fact that mutations are independent of one another, they can be performed concurrently. In fact, as we will see in the future articles, mutating and scoring are the only steps that can be easily run in parallel.\nA diagram showing the flow of actions applied on a single generation.\nThrowing a rectangular dice Rectangles are the easiest shape to draw both algorithmically and IRL; our first mutator will use rectangles as a mutation primitive. To generate a random rectangle we need have the following:\ncoordinates of one of its corners, width, height, fill color. Fill color is pretty straightforward, but other values have some constraints they need to meet. An image we\u0026rsquo;ll be mutating has width and height \u0026ndash; let\u0026rsquo;s assume it\u0026rsquo;s n and m respectively. Coordinates of one of the corners, in our case it\u0026rsquo;s going to be top-left, are limited by the image dimensions. Width and height are limited by both image dimensions, and the coordinates we just generated.\n$$ x \\in \\lbrack 0 .. n \\lbrack \\newline y \\in \\lbrack 0 .. m \\lbrack \\newline width \\in \\lbrack 1 .. n - x + 1 \\lbrack \\newline height \\in \\lbrack 1 .. m - y + 1 \\lbrack \\newline $$\nWhy coordinates intervals are right-open? Because if the mutator selects the very right or bottom edge, then the rectangle would need to have zero width/height. By not right-closing the intervals, we ensure that there\u0026rsquo;s at least one pixel which can be mutated üëå. Similarly both width and height intervals are right-open to ensure that the rectangle will not overflow the image.\nstruct RandomRectangle { x: usize, y: usize, width: usize, height: usize, } #[must_use] fn get_random_rectangle(random: \u0026amp;mut Random, image: \u0026amp;Image) -\u0026gt; RandomRectangle { let image_width = image.width(); let image_height = image.height(); let x = random.get_random(0usize, image_width); let y = random.get_random(0usize, image_height); let width = random.get_random(0usize, image_width - x) + 1; let height = random.get_random(0usize, image_height - y) + 1; RandomRectangle { x, y, width, height, } } Function get_random_rectangle is a neat helper: based on the given RNG2 and image, it returns a struct representing a random rectangle within the boundaries of the image.\nOnly two things left to do: generate random color and draw the shape. The implementation of rectangle mutator will look like this:\n#[derive(Debug, Default)] pub struct RectangleMutator; impl Mutator for RectangleMutator { fn mutate(\u0026amp;self, image: \u0026amp;mut Image) { let mut random = Random::default(); let rect = get_random_rectangle(\u0026amp;mut random, image); let r = random.get_random(0u8, 255); let g = random.get_random(0u8, 255); let b = random.get_random(0u8, 255); let image_width = image.width(); for j in rect.y..(rect.height + rect.y) { for i in rect.x..(rect.width + rect.x) { let pixel = \u0026amp;mut image[j * image_width + i]; pixel.r(r); pixel.g(g); pixel.b(b); } } } } The implementation is really simple. First we get a random rectangle (using the helper function), then generate color channels, and finally draw the shape. Drawing itself is done by two nested loops iterating over columns and rows of the image. With the two indexes it references a specific pixel: j * image_width + 1 and finally overrides it using the color channels.\nCool, let\u0026rsquo;s see what the program generates after 10 000 generations when initialized with \u0026ldquo;Mona Lisa\u0026rdquo;.\nMona Lisa (generation #10 000) Doesn\u0026rsquo;t really looks like anything. üòê\nWhich isn\u0026rsquo;t very surprising; the code did what it was suppose to do: it generated random rectangles on the white image. Since we don\u0026rsquo;t have any scoring logic yet (that\u0026rsquo;s a topic for another article) the resulting image is composed of random noise. We\u0026rsquo;ll need to wait a bit longer to get an image that even remotely reflects \u0026ldquo;Mona Lisa\u0026rdquo;.\nThrowing dice of other shapes It\u0026rsquo;d be nice to have mutators other than RectangleMutator, which are able to mutate images with different shapes, but I\u0026rsquo;m not going to cover them here. The reason is simple \u0026ndash; they operate under the same rules: you need to define boundaries first and then you need to draw the desired shape. I\u0026rsquo;ve implemented two other mutators: TriangleMutator and CircleMutator. Their sources can be found here.\nAfterword You might\u0026rsquo;ve noticed that the code examples of this article are not strictly bounded together, meaning you cannot just copy them to have a working example. A bunch of things like: Random implementation, loading the original image, mutation loop, and the whole impl Image block are missing. If you want to have a working solution it\u0026rsquo;s here (locked down to the newest commit at the moment of writing \u0026ndash; 73aa8da). The goal of this series is not to go through every single line of code to build a working utility, but rather to present an idea. So, moving forward all future articles from this series will also be done in that style.\nPhoto by Alexander Grey on Unsplash\nStay tuned üåä\nUsually the generation is generated randomly. See here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRandom is a project-private utility class. Source can be found here.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://madebyme.today/articles/franklin/randomness-of-life/","summary":"In the previous article from this series, we\u0026rsquo;ve talked about genetic algorithms and how they can be used to generate art. Now let\u0026rsquo;s put those ideas into action and focus on implementing the first part of our artistic toolset: mutators.\n","tag":"Rust","title":"Randomness of Life"}]
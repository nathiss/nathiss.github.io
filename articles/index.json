[{"content":"Recently I was tasked with initialization of a new Python project. One of the requirements was to prepare a changelog. I liked the idea, but my gut feeling was that the future project contributors won\u0026rsquo;t keep the changelog always up-to-date and it\u0026rsquo;s quality will decline over time. This article proposes a feature which enforces changelog updates, when it\u0026rsquo;s required to do so.\nWhat\u0026rsquo;s a changelog A changelog is a log or record of all notable changes made to a project. The project is often a website or software project, and the changelog usually includes records of changes such as bug fixes, new features, etc.\nfrom Wikipedia.\nThe phrase \u0026ldquo;notable changes\u0026rdquo; is the key here. Not all changes to the project are required to have an entry in its changelog: workflow updates, typo fixes in README, SonarQube settings; they all are transparent to the Python package produced by the project.\nLet\u0026rsquo;s take a look at an example:\n. ‚îú‚îÄ .github ‚îÇ ‚îî‚îÄ workflows ‚îÇ ‚îî‚îÄ‚îÄ workflow.yaml ‚îú‚îÄ docs ‚îÇ ‚îú‚îÄ conf.py ‚îÇ ‚îú‚îÄ index.rst ‚îÇ ‚îî‚îÄ Makefile ‚îú‚îÄ foo ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îî‚îÄ bar ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îî‚îÄ baz.py ‚îú‚îÄ tests ‚îÇ ‚îú‚îÄ __init__.py ‚îÇ ‚îî‚îÄ test_bar.py ‚îú‚îÄ .gitignore ‚îú‚îÄ README.md ‚îú‚îÄ Makefile ‚îú‚îÄ setup.py ‚îú‚îÄ Manifest.in ‚îú‚îÄ pyproject.toml ‚îî‚îÄ Changelog.md This is a pretty standard (and also minimalistic!) take on a Python project. The pipeline defined in .github/workflows/workflow.yaml builds, tests and publishes the package. Initially project stored its version in pyproject.toml, while Changelog.md contained human-readable lists of additions, fixes, and improvements for each release. Having a standard usually makes things easier, so we adopted keep a changelog, which also uses Semantic Versioning 2.0.0, so that was nice.\nKeep a changelog is just a Markdown template \u0026ndash; it has no associated toolset. Here\u0026rsquo;s an example of a changelog with two entries:\n# Changelog All notable changes to this project will be documented in this file. The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/), and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html). ## [1.2.0] - 2023-10-01 ### Added - Support for Python 3.12. - Utility for parsing `foo`. ### Fixed - Worker subprocesses are now correctly closed. ### Changed - Update `pylint` version to `~= 2.17`. ## [1.1.2] - 2019-02-15 ### Fixed - Typo in project\u0026#39;s title in docs. Keep(ing) a changelog up-to-date When releasing a new package version one needs to remember to update the version in two places: pyproject.toml and Changelog.md. Also, there\u0026rsquo;s no mechanism to enforce that behavior; we could create a workflow step to validate that both places are in sync, but relaying on CI to inform contributors about the necessary changes seems far from ideal.\nInstead, we made Changelog.md the only place where the version can be updated. pyproject.toml expects the version to be statically defined; we can disable that behavior by marking the version as dynamic.\n[build-system] requires = [\u0026#34;setuptools\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;foo\u0026#34; readme = \u0026#34;README.md\u0026#34; requires-python = \u0026#34;\u0026gt;=3.9\u0026#34; dependencies = [ \u0026#34;requests\u0026#34;, ] dynamic = [\u0026#34;version\u0026#34;] # \u0026lt;---- The version still needs to be defined somewhere, and using setup.py for that purpose gives us an advantage \u0026ndash; we can execute an arbitrary Python code there.\nimport re from pathlib import Path from typing import Generator from setuptools import setup def __get_versions() -\u0026gt; Generator[tuple[int, int, int], None, None]: dir_name = Path(__file__).parent with open(dir_name / \u0026#34;Changelog.md\u0026#34;, \u0026#34;r\u0026#34;) as file: lines = file.readlines() for line in lines: m = re.match(r\u0026#34;^##\\s+\\[(\\d+\\.\\d+\\.\\d+)\\]\u0026#34;, line) if m: x, y, z = m.group(1).split(\u0026#34;.\u0026#34;, 2) yield int(x), int(y), int(z) def __get_highest_version() -\u0026gt; str: highest_version = max(__get_versions()) return \u0026#34;.\u0026#34;.join(map(str, highest_version)) setup( version=__get_highest_version(), ) Now the only place where package\u0026rsquo;s version needs to be updated is the changelog itself. Note that this change does not enforce updating the changelog for every change. However, to release a new version of the package one is required to add a new changelog entry.\nNow, since the presence of Changelog.md is necessary for the build to succeed, we should inform the build system about this dependency. MANIFEST.in contains include/exclude patters for non-standard files (see official docs). Add the following line to the manifest:\n# ... include Changelog.md Accessing project version from Sphinx Sphinx is a most popular tool for generating documentation out of Python source files. It keeps its configuration in the conf.py file, which has two special attributes related to the project\u0026rsquo;s version:\nversion \u0026ndash; the major project version (see official documentation), release \u0026ndash; the full project version (see official documentation). With the current setup it\u0026rsquo;s hard for Sphinx to read the version, since it\u0026rsquo;s only accessible from setup.py. The easiest workaround is to extract the parsing to an external module and then use that module as a dependency in both conf.py and setup.py.\n# version.py import re from pathlib import Path from typing import Generator from setuptools import setup def __get_versions() -\u0026gt; Generator[tuple[int, int, int], None, None]: dir_name = Path(__file__).parent with open(dir_name / \u0026#34;Changelog.md\u0026#34;, \u0026#34;r\u0026#34;) as file: lines = file.readlines() for line in lines: m = re.match(r\u0026#34;^##\\s+\\[(\\d+\\.\\d+\\.\\d+)\\]\u0026#34;, line) if m: x, y, z = m.group(1).split(\u0026#34;.\u0026#34;, 2) yield int(x), int(y), int(z) def __get_highest_version() -\u0026gt; str: highest_version = max(__get_versions()) return \u0026#34;.\u0026#34;.join(map(str, highest_version)) version = __get_highest_version() After that we can import the module in setup.py:\nfrom setuptools import setup from version import version print(version) setup( version=__get_highest_version(), ) \u0026hellip; and conf.py:\nimport sys from pathlib import Path project = \u0026#34;foo\u0026#34; copyright = \u0026#34;2023\u0026#34; author = \u0026#34;Kamil Rusin\u0026#34; root_dir = Path(__file__).parents[1] sys.path.insert(0, str(root_dir)) from version import version as __project_version version = __project_version release = version Again, we cannot forget about informing the build system about the new dependency in MANIFEST.in:\n# ... include Changelog.md include version.py Afterthought Maintaining a changelog can make a project easier to understand. Hopefully, with the changes proposed in this article you\u0026rsquo;ll find changelogs more manageable. This feature does not enforce changelog updates from the contributors \u0026ndash; they will only need to do so, when they want to release a new version of the package.\nI highly encourage to always release a new version even for the smallest change in the project sources that is observable for the users. Whether it\u0026rsquo;s worth to add changelog entries for project\u0026rsquo;s meta updates, is up to you.\nPhoto by Jasper Garratt on Unsplash\n","permalink":"https://madebyme.today/articles/keep-a-changelog/","section":"Articles","summary":"Recently I was tasked with initialization of a new Python project. One of the requirements was to prepare a changelog. I liked the idea, but my gut feeling was that the future project contributors won\u0026rsquo;t keep the changelog always up-to-date and it\u0026rsquo;s quality will decline over time. This article proposes a feature which enforces changelog updates, when it\u0026rsquo;s required to do so.\n","title":"Keep a Changelog"},{"content":"Recently I\u0026rsquo;m investing a lot of time to developing a game server in Rust. I started with implementing network layer based on WebSockets. It\u0026rsquo;s far from being ready, but I developed a helper crate for creating detached, cancellable services.\nGame server backstory The idea of developing an authoritative game server always seemed appealing to me. Network programming, however, has many pitfalls:\nServer need to validate all use inputs to protect game state from bad actors. Ill-formed data sent by one client should not deny service for another player. Async programming is hard in general. So, in the past I have had many attempts to develop a game server. Each improving on mistakes made in the previous one.\nspectrum-old \u0026ndash; A real-time multiplayer browser game, Fusion-cpp \u0026ndash; This is the source code of the server for the Fusion game, [private repo], [private repo], [private repo]. And now I\u0026rsquo;m working on another. üëç\nThis time, improvements over the previous one are creating implementation that depend on traits and organizing TODOs to a single GitHub project.\nMaking Progressxkcd #1906\nCancellable crate Network functionalities in game servers (listeners, TCP streams, etc.) await for some input and usually yield a result.\nComponent Input Output Listener new incoming connection Client object TCP Stream data package parsed ClientMessage model Ping service timer tick new ping frame We can define a trait that will describe common interface for all of them:\n#[async_trait::async_trait] pub trait Cancellable { type Result; type Error; async fn run(\u0026amp;mut self) -\u0026gt; Result\u0026lt;CancellationResult\u0026lt;Self::Result\u0026gt;, Self::Error\u0026gt;; } Method run performs a single unit of work of the service. Internally it can await for the input to be available and then return its result. If the returned value is Err(Self::Error) then the service completes. If it succeeds, then it should return Ok(CancellationResult). CancellationResult is an enum defined as follows:\npub enum CancellationResult\u0026lt;T\u0026gt; { Item(T), Continue, Break, } impl\u0026lt;T\u0026gt; CancellationResult\u0026lt;T\u0026gt; { pub fn item(t: impl Into\u0026lt;T\u0026gt;) -\u0026gt; Self { Self::Item(t.into()) } } Enum\u0026rsquo;s variant control whether the service will continue to perform its work. If the service produces a value, then it should wrap it as CancellableResult::Item(t); it\u0026rsquo;s also a signal that the service should continue to work. If no value is available, but the service should continue then it returns CancellableResult::Continue (similar to Poll::Pending).\nIf the service finishes its work successfully (e.g. when the peer closes the connection) then the service should return CancellableResult::Break.\nCancellable trait has methods for spawning the service as a detached, background task:\n#[async_trait::async_trait] pub trait Cancellable { // ... async fn spawn(mut self, cancellation_token: CancellationToken) -\u0026gt; CancellableHandle\u0026lt;Self\u0026gt; { // ... } async fn spawn_with_callback\u0026lt;F\u0026gt;( mut self, cancellation_token: CancellationToken, mut callback: F, ) -\u0026gt; CancellableHandle\u0026lt;Self\u0026gt; where F: FnMut(Self::Result) -\u0026gt; Result\u0026lt;(), Self::Result\u0026gt; { // ... } } Both return a handle, which can be awaited for the service to complete, once it has been cancelled!\nIf the service produces results, then it can be spawned with spawn_with_callback, to consume them. If the callback returns Err(Self::Result) then the service completes immediately.\nThis setup offers a way of detaching services which perform work \u0026ldquo;on their own\u0026rdquo;, but sometimes services need to accept additional data. An example is TCP stream: it reads data packages from a peer and consumes them via callback. However, if the server decides the connection should be terminated, then the service should complete its work.\nEnter\u0026hellip;\nCommunicating with detached service When we spawn the service task we already get a handle:\nlet token = CancellableToken::new(); let handle = service.spawn(token.clone()).await; The handle can be used as an interface to send data to its service.\nhandle.update(ConnectionStatus::TerminatedByServer(reason)); The actual interface needs to be implementation-dependent \u0026ndash; defined in the Cancellable trait. By easily extending the trait we get:\n#[async_trait::async_trait] pub trait Cancellable { // ... type Handle; async fn new_handle(\u0026amp;mut self) -\u0026gt; Self::Handle; } When the service is spawned (either by spawn or spawn_with_callback), the method will call new_handle to construct the handle. The handle is owned by CancellableHandle, which implements Deref for Self::Handle type. With that setup, we can define a channel by which spawner can communicate with spawnee.\nI like the final product, so I\u0026rsquo;ve packaged it as a crate. It\u0026rsquo;s available on crates.io.\nüåä\n","permalink":"https://madebyme.today/articles/cancellable/","section":"Articles","summary":"Recently I\u0026rsquo;m investing a lot of time to developing a game server in Rust. I started with implementing network layer based on WebSockets. It\u0026rsquo;s far from being ready, but I developed a helper crate for creating detached, cancellable services.\n","title":"Cancellable"},{"content":"Today I was again setting up OpenPGP application on a new Yubikey. After over two years I already forgot how tedious that can be\u0026hellip; I\u0026rsquo;m writing this blog post to create a clear trace of what I needed to do today and hopefully, when the time comes to set up an another key, it\u0026rsquo;ll be as easy as opening up a blog entry.\nIn general I started to learn about security keys a few years back. I read \u0026ldquo;Security Keys: Practical Cryptographic Second Factors for the Modern Web\u0026rdquo; research paper by Google, explaining how they work and how they made them \u0026ldquo;fool-proof\u0026rdquo;. The article is very detailed and yet written in a easy-to-follow way. If you\u0026rsquo;re interested in security, then give it a try!\nThe rest of this article is a ramp about configuring a new key. If you don\u0026rsquo;t have one/not having issues with one at the moment, you can give it amiss.\nSetting up a new key Yubico offers great software for managing your keys. If you\u0026rsquo;re planning on using yours as a 2FA method or FIDO2, then you are a happier person.\nYubikey \u0026amp; macOS To start with, I could not make the key detectable by GnuPG. I was getting \u0026ldquo;Operation not supported by device\u0026rdquo; error.\ngpg --card-status gpg: selecting card failed: Operation not supported by device gpg: OpenPGP card not available: Operation not supported by device Then I found DataDog\u0026rsquo;s Yubikey troubleshooting guide. It fixed my problem \u0026ndash; a config file was missing in my GnuPG home.\nYubikey \u0026amp; OpenPGP Working with gpg sucks.\nThe tool is very advanced and offering a lot of features, so naturally its CLI is complex, to say the least. As it was before, so it was now, I was saved by this marvelous guide on how to prepare PGP keys for a Yubikey.\nIt encompasses everything: from generating keys, to rotating keys. It also offers different solutions depending on how much you care about security. I highly encourage you to configure your key with this guide.\nIt got me through most of the OpenPGP stuff pretty smoothly. Again, I was lost on making the key work with gpg-agent.\nYubikey \u0026amp; SSH Once all three keys (Signing, Encryption, Authentication) are correctly set up, it\u0026rsquo;s the moment for the agent. I always miss two parts: configuring gpg-agent and enabling SSH for gpg-agent.\nThe first one requires these few lines at the end of your rc file. I use Z shell, so it\u0026rsquo;s .zshrc for me.\nEnabling SSH for gpg-agent can be done by adding gpg-agent.conf file to your GnuPG home.\nYou\u0026rsquo;ll probably need to update the path pointing to pinentry-program. Just run\nwhich pinentry-mac If you don\u0026rsquo;t have pinentry-mac installed, then\nbrew install pinentry Cool. The last and yet very important step is to relaunch the agent:\ngpgconf --kill gpg-agent It should hopefully work.\nTips To get public SSH key run: ssh-add -L. It was around that time, when I tried to fetch my remote repo from GitHub\u0026hellip; and it wasn\u0026rsquo;t working. I lost a significant amount of time looking for some configuration issue, but there wasn\u0026rsquo;t any. I redid everything again to no avail.\nThen I saw that some of my GitHub Actions are not being triggered. ü§î I dig a bit more and it turned out GitHub was having issues.\nGitHub Status is a great site to keep in your RSS feed. When issues arise, they cascade.\n","permalink":"https://madebyme.today/articles/how-to-security-keys/","section":"Articles","summary":"Today I was again setting up OpenPGP application on a new Yubikey. After over two years I already forgot how tedious that can be\u0026hellip; I\u0026rsquo;m writing this blog post to create a clear trace of what I needed to do today and hopefully, when the time comes to set up an another key, it\u0026rsquo;ll be as easy as opening up a blog entry.\n","title":"How to: Security Keys"},{"content":"","permalink":"https://madebyme.today/articles/franklin/","section":"Articles","summary":"","title":"Franklin"},{"content":"Well it took some time (almost 6 years) to create a personal blog, but here we are.\nHow did we come here? This is not the first attempt on creating my own website. On my GitHub there are many (most of them private) repos, which contains some sort of personal website. All of them abandoned, but not this one!\n\u0026hellip; at least not yet. ‚úå(-‚Äø-)‚úå However I\u0026rsquo;m optimistic.\nTo better understand why I have such high hopes for this project let\u0026rsquo;s go down the rabbit hole and analyze its ancestors and try to point out why they failed.\nPlatform 1: 0x52 (Django 2.2) Django is one of the first tools I\u0026rsquo;ve ever used to create something on the web.\nDjango is a high-level Python web framework that encourages rapid development and clean, pragmatic design. Built by experienced developers, it takes care of much of the hassle of web development, so you can focus on writing your app without needing to reinvent the wheel. It‚Äôs free and open source.\n~ Django website\nUsing that framework I\u0026rsquo;ve built a web journal. The idea was that at any moment I could use one of my devices to create a new journal entry. They were automatically sorted by creation date and tagged with tokens retrieved from the entry\u0026rsquo;s content. The latter deserves a bit more digging into, so let\u0026rsquo;s consider the following entry:\nLorem ipsum @dolor sit amet, consectetur adipiscing elit. Aliquam sed eleifend magna. @Quisque venenatis ex ex, a suscipit purus iaculis ac. Sed @lacinia tincidunt nunc vitae consectetur.\nA tag is a sequence of characters between '@' and one of ',\u0026lt;.\u0026gt;/?;:\\'\u0026quot;[{]}\\\\|()=+#$%^\u0026amp;*~\\r\\n '. When an entry was either created or modified, then the logic extracted tags from content:\n@staticmethod def extract_tag_names(text): words = re.split(Tag.escape_delimiters(Tag.TAG_DELIMITERS), text) words = list(filter(None, words)) return [tag_name[1:].lower() for tag_name in words if tag_name.startswith(Tag.TAG_SYMBOL)] It worked pretty well. I could create a new tag or use an already existing one. When the tag was orphaned (meaning it was referenced by no entry) the logic was able to take care of that too. üëÄ\nThe solution was designed to be used by more that one user: each person would have an account and they would be able to access only their own entries and tags.\nWhat happened with that project? I used it for a while, but after some time I wasn\u0026rsquo;t really actively adding new entries, so it just fated away. Also it was more of a personal utility website, than a blog. It was publicly available on Heroku until quite recently actually. I took down the website when Heroku announced their removal of free product plans.\nPlatform 2: Titan (ASP.NET) This was an another iteration of personal website development. I\u0026rsquo;ve decided to use .NET for this one, because earlier in that year I got my first job in the field and I was hyped to build something with the technology we used at work (we were developing a few solutions and one of them was built on top of .NET Framework).\nSadly I deleted the source code some time ago as a part of my GitHub purge, but I remember quite vividly the problem(s) with this one. In a sentence: it was too overengineered.\nthe strategy is definitely: first make it work, then make it right, and, finally, make it fast.\n~ \u0026ldquo;The C Language and Models for Systems Programming\u0026rdquo; in Byte magazine (August 1983)\nI wanted to use JWT as a user authentication method. I\u0026rsquo;ve read on many places on the web that it\u0026rsquo;s a bad idea, but still I was devoted to make it work. One of the issues I was aware of was that you cannot easily and permanently logout a user when using JWT.\nIn a nutshell JWT are tokens stored on the client-side. However, due to encryption, they can only be read by the service. So with each request the client sends its token to the sever (like a cookie, you might say). If the token is well-formed, then the server, with quite high certainty, can assume it wasn\u0026rsquo;t tinkered with.\nGoing back to logout issue: to ensure that session will not last indefinitely the server could add \u0026quot;expiryDate\u0026quot; field to payload and check its value with each request and respond accordingly. That works pretty well. The client has no way of modifying \u0026quot;expiryDate\u0026quot;.\nYet it\u0026rsquo;s much harder to kill the session before token expiries. My attempt was to add a new field to token\u0026rsquo;s payload which would indicate that its no longer valid and send it back to the client. The problem though is that the client does not need to use the new token. It still can use the old one and, since we don\u0026rsquo;t store session information on the server, the service has not way of detecting that. üí¢\nThe solution I came up with was to use Redis. To store that information on the server-side.\nRedis: The open source, in-memory data store used by millions of developers as a database, cache, streaming engine, and message broker.\nOnce the server decides the user should be logged out, it will store JWT\u0026rsquo;s ID in Redis alongside with an indication of whether the session has ended.\nCan you see now when I said it was overengineered? So many complex solutions for a logout functionality. The project ended because I was too wornout to finish it.\nPlatform 3: Polaris (React) I\u0026rsquo;m actually quite proud of this one. It\u0026rsquo;s a static website running on React and hosting my vector graphics. It\u0026rsquo;s painfully simple, but that was kinda the point. I wanted to have a way of hosting those images ASAP, hence React and GitHub Pages, where the website is actually hosted.\nIt wasn\u0026rsquo;t my first contact with technologies used in frontend, but it was the first time when I used state of the art tools for a new website. My knowledge of NodeJS and utilities built on top of it was practically nonexistent. That changed once I\u0026rsquo;ve written Polaris; now I\u0026rsquo;m just new to this stuff.\nSteam on the horizon I don\u0026rsquo;t have much more to say here other that, it was a while when I\u0026rsquo;ve used Inkscape to create those images and when I needed to use it again, for the sake of this blog, it was terrifying to see how much one can forget what one has learned. ‡≤†_‡≤†\nPlatforms long forgotten There were many more projects which aimed to create my personal space on the web, but only these mentioned above are still remembered by me enough to write a few sentences about.\nIt\u0026rsquo;s safe to say they all suffered from the same fundamental flaws:\nthey were too complex, they were trying to solve all possible future problem without aiming to deliver the most basic functionality, backend is hard. This blog, on the other hand, is a static content website build with Hugo. I think to some extend I was aware that tools like Hugo existed, but I\u0026rsquo;ve never considered using them. I cannot really explain as to why; maybe I was trying too hard to use a new fancy tool I\u0026rsquo;ve just learned about.\nThe goal and future of this project The goal of this project is to create an archive for stuff I\u0026rsquo;m going to learn. It\u0026rsquo;s still unclear as to what I\u0026rsquo;m going to post on this blog, but it\u0026rsquo;s safe to say that it\u0026rsquo;s going to be techy.\nI cannot say with any amount of certainty how often I\u0026rsquo;ll be writing new articles. I\u0026rsquo;m really looking forward to making new content though. I believe it will also tilt me significantly into learning about new things.\nThere are still some adjustments I need to make on the website, I\u0026rsquo;m probably going to focus on them before I\u0026rsquo;ll work on new articles, but in general it is functionally complete.\nSo as of now, thank you for reading.\nüåä\n","permalink":"https://madebyme.today/articles/beginnings-are-hard/","section":"Articles","summary":"Well it took some time (almost 6 years) to create a personal blog, but here we are.\n","title":"Beginnings Are Hard"}]